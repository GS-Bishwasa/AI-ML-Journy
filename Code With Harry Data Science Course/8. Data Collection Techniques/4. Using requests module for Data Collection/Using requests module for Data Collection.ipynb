{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0acab79e",
   "metadata": {},
   "source": [
    "# Using `requests` Module for Data Collection\n",
    "\n",
    "Today we will see how to scrape websites and use the `requests` module to download the raw HTML of a webpage.  \n",
    "For demo purposes, we can safely use:\n",
    "- [Quotes to Scrape](https://quotes.toscrape.com/)\n",
    "- [Books to Scrape](https://books.toscrape.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f658c2",
   "metadata": {},
   "source": [
    "## 1. What is `requests`?\n",
    "\n",
    "- `requests` is a Python library used to send HTTP requests easily.\n",
    "- It allows you to fetch the content of a webpage programmatically.\n",
    "- Commonly used as the first step before parsing HTML with BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ae82ea",
   "metadata": {},
   "source": [
    "## 2. Installing `requests`\n",
    "\n",
    "To install `requests`, run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62acfcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b1666",
   "metadata": {},
   "source": [
    "## 3. Sending a Basic GET Request\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a5e6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://example.com\"\n",
    "response = requests.get(url)\n",
    "\n",
    "# Print the HTML content\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e821c87",
   "metadata": {},
   "source": [
    "**Key Points:**\n",
    "- `url`: The website you want to fetch.\n",
    "- `response.text`: The HTML content of the page as a string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7af0004",
   "metadata": {},
   "source": [
    "## 4. Checking the Response Status\n",
    "\n",
    "Always check if the request was successful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7968e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557df29c",
   "metadata": {},
   "source": [
    "**Common Status Codes:**\n",
    "- `200`: OK (Success)\n",
    "- `404`: Not Found\n",
    "- `403`: Forbidden\n",
    "- `500`: Internal Server Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a12d3db",
   "metadata": {},
   "source": [
    "**Good practice:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce2339e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if response.status_code == 200:\n",
    "    print(\"Page fetched successfully!\")\n",
    "else:\n",
    "    print(\"Failed to fetch the page.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7527a058",
   "metadata": {},
   "source": [
    "## 5. Important Response Properties\n",
    "\n",
    "| Property             | Description                              |\n",
    "|----------------------|------------------------------------------|\n",
    "| `response.text`      | HTML content as Unicode text             |\n",
    "| `response.content`   | Raw bytes of the response                |\n",
    "| `response.status_code` | HTTP status code                      |\n",
    "| `response.headers`   | Metadata like content-type, server info  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c0eff1",
   "metadata": {},
   "source": [
    "## 6. Adding Headers to Mimic a Browser\n",
    "\n",
    "Sometimes websites block automated requests. Adding a `User-Agent` header helps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b3129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12bead4",
   "metadata": {},
   "source": [
    "## 7. Handling Connection Errors\n",
    "\n",
    "Wrap your request in a try-except block to handle errors gracefully:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2032a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = requests.get(url, timeout=5)\n",
    "    response.raise_for_status()  # Raises an HTTPError for bad responses\n",
    "    print(response.text)\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a29bc0",
   "metadata": {},
   "source": [
    "## 8. Best Practices for Fetching Pages\n",
    "\n",
    "- Always check the HTTP status code.\n",
    "- Use proper headers to mimic a browser.\n",
    "- Set a timeout to avoid hanging indefinitely.\n",
    "- Respect the website by not making too many rapid requests."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12c3d8",
   "metadata": {},
   "source": [
    "## 9. Summary\n",
    "\n",
    "- `requests` makes it simple to fetch web pages using Python.\n",
    "- It is the starting point for most web scraping workflows.\n",
    "- Combining `requests` with BeautifulSoup allows for powerful data extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad562a38-ac03-4a19-b199-5b3cf74d9897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efe32c7b-326a-46e3-a87b-b399b17cf9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = requests.get('https://books.toscrape.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85e000c4-37fe-4204-ac3f-f47368328e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,51):\n",
    "    a = requests.get(f\"https://books.toscrape.com/catalogue/page-{i}.html\")\n",
    "    with open(f\"htmls/page{i}.html\",'w',encoding=\"utf\") as f:\n",
    "        f.write(a.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51cdb92a-17fe-4019-8bd5-85a38f853f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully!\n"
     ]
    }
   ],
   "source": [
    "if a.status_code == 200:\n",
    "    print(\"Page fetched successfully!\")\n",
    "else:\n",
    "    print(\"Failed to fetch the page.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6017dbfc-ce3d-4d95-b08f-b5582040592a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
